{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Field          | Description                                                                           |\n",
    "|----------------|---------------------------------------------------------------------------------------|\n",
    "| |\t|\n",
    "| |\t|\n",
    "| |\t|\n",
    "| |\t|\n",
    "| |\t|\n",
    "| |\t|\n",
    "| |\t|\n",
    "| |\t|\n",
    "| |\t|\n",
    "| |\t|\n",
    "| |\t|\n",
    "| |\t|\n",
    "| |\t|\n",
    "| |\t|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation for Action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(60000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 60 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import count_nonzero, median, mean\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "#import squarify\n",
    "\n",
    "\n",
    "# import statsmodels.api as sm\n",
    "# import statsmodels.formula.api as smf\n",
    "# from statsmodels.formula.api import ols\n",
    "# Import variance_inflation_factor from statsmodels\n",
    "# from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "# Import Tukey's HSD function\n",
    "# from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "import datetime\n",
    "from datetime import datetime, timedelta, date\n",
    "\n",
    "# import shap\n",
    "# import eli5\n",
    "# from IPython.display import display\n",
    "\n",
    "#import os\n",
    "#import zipfile\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy.stats.mstats import normaltest # D'Agostino K^2 Test\n",
    "from scipy.stats import boxcox\n",
    "from collections import Counter\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, OneHotEncoder, PolynomialFeatures\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "\n",
    "from sklearn.metrics import accuracy_score, auc, classification_report, confusion_matrix, f1_score, roc_auc_score\n",
    "from sklearn.metrics import precision_score, recall_score, ConfusionMatrixDisplay, RocCurveDisplay\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.feature_selection import f_regression, f_classif, chi2, RFE, RFECV\n",
    "from sklearn.feature_selection import mutual_info_regression, mutual_info_classif\n",
    "from sklearn.feature_selection import VarianceThreshold, GenericUnivariateSelect\n",
    "from sklearn.feature_selection import SelectFromModel, SelectKBest, SelectPercentile\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB, CategoricalNB\n",
    "\n",
    "import imblearn\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler, CondensedNearestNeighbour\n",
    "from imblearn.under_sampling import EditedNearestNeighbours, TomekLinks\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "\n",
    "\n",
    "import feature_engine\n",
    "\n",
    "from feature_engine.selection import DropConstantFeatures, DropDuplicateFeatures \n",
    "from feature_engine.selection import DropCorrelatedFeatures, SmartCorrelatedSelection\n",
    "from feature_engine.selection import SelectBySingleFeaturePerformance\n",
    "\n",
    "import pycaret\n",
    "from pycaret.classification import *\n",
    "\n",
    "%matplotlib inline\n",
    "#sets the default autosave frequency in seconds\n",
    "%autosave 60 \n",
    "sns.set_style('dark')\n",
    "sns.set(font_scale=1.2)\n",
    "\n",
    "plt.rc('axes', titlesize=9)\n",
    "plt.rc('axes', labelsize=14)\n",
    "plt.rc('xtick', labelsize=12)\n",
    "plt.rc('ytick', labelsize=12)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# This module lets us save our models once we fit them.\n",
    "# import pickle\n",
    "\n",
    "pd.set_option('display.max_columns',None)\n",
    "#pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.float_format','{:.2f}'.format)\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Data Glance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"calibdata2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annualinc</th>\n",
       "      <th>collections</th>\n",
       "      <th>delinq</th>\n",
       "      <th>inq</th>\n",
       "      <th>openacc</th>\n",
       "      <th>dti</th>\n",
       "      <th>pubrec</th>\n",
       "      <th>individual</th>\n",
       "      <th>mortgage</th>\n",
       "      <th>rent</th>\n",
       "      <th>own</th>\n",
       "      <th>other</th>\n",
       "      <th>term60mths</th>\n",
       "      <th>vstatusverified</th>\n",
       "      <th>vstatusnotverified</th>\n",
       "      <th>lstatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   annualinc  collections  delinq  inq  openacc  dti  pubrec  individual  mortgage  rent  own  other  term60mths  vstatusverified  vstatusnotverified  lstatus\n",
       "0       0.02         0.00    0.00 0.06     0.47 0.59    0.00           1         1     0    0      0           1                1                   0        0\n",
       "1       0.00         0.00    0.00 0.00     0.12 0.57    0.00           1         0     1    0      0           0                0                   1        0\n",
       "2       0.01         0.00    0.00 0.03     0.16 0.34    0.00           1         0     1    0      0           0                1                   0        0\n",
       "3       0.00         0.00    0.00 0.00     0.18 0.21    0.00           1         1     0    0      0           0                0                   1        0\n",
       "4       0.01         0.00    0.00 0.00     0.30 0.59    0.00           1         0     1    0      0           0                1                   0        0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 49986 entries, 0 to 49985\n",
      "Data columns (total 16 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   annualinc           49986 non-null  float64\n",
      " 1   collections         49986 non-null  float64\n",
      " 2   delinq              49986 non-null  float64\n",
      " 3   inq                 49986 non-null  float64\n",
      " 4   openacc             49986 non-null  float64\n",
      " 5   dti                 49986 non-null  float64\n",
      " 6   pubrec              49986 non-null  float64\n",
      " 7   individual          49986 non-null  int64  \n",
      " 8   mortgage            49986 non-null  int64  \n",
      " 9   rent                49986 non-null  int64  \n",
      " 10  own                 49986 non-null  int64  \n",
      " 11  other               49986 non-null  int64  \n",
      " 12  term60mths          49986 non-null  int64  \n",
      " 13  vstatusverified     49986 non-null  int64  \n",
      " 14  vstatusnotverified  49986 non-null  int64  \n",
      " 15  lstatus             49986 non-null  int64  \n",
      "dtypes: float64(7), int64(9)\n",
      "memory usage: 6.1 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int64      9\n",
       "float64    7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annualinc</th>\n",
       "      <th>collections</th>\n",
       "      <th>delinq</th>\n",
       "      <th>inq</th>\n",
       "      <th>openacc</th>\n",
       "      <th>dti</th>\n",
       "      <th>pubrec</th>\n",
       "      <th>individual</th>\n",
       "      <th>mortgage</th>\n",
       "      <th>rent</th>\n",
       "      <th>own</th>\n",
       "      <th>other</th>\n",
       "      <th>term60mths</th>\n",
       "      <th>vstatusverified</th>\n",
       "      <th>vstatusnotverified</th>\n",
       "      <th>lstatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>49986.00</td>\n",
       "      <td>49986.00</td>\n",
       "      <td>49986.00</td>\n",
       "      <td>49986.00</td>\n",
       "      <td>49986.00</td>\n",
       "      <td>49986.00</td>\n",
       "      <td>49986.00</td>\n",
       "      <td>49986.00</td>\n",
       "      <td>49986.00</td>\n",
       "      <td>49986.00</td>\n",
       "      <td>49986.00</td>\n",
       "      <td>49986.00</td>\n",
       "      <td>49986.00</td>\n",
       "      <td>49986.00</td>\n",
       "      <td>49986.00</td>\n",
       "      <td>49986.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       annualinc  collections   delinq      inq  openacc      dti   pubrec  individual  mortgage     rent      own    other  term60mths  vstatusverified  vstatusnotverified  lstatus\n",
       "count   49986.00     49986.00 49986.00 49986.00 49986.00 49986.00 49986.00    49986.00  49986.00 49986.00 49986.00 49986.00    49986.00         49986.00            49986.00 49986.00\n",
       "mean        0.01         0.00     0.01     0.02     0.19     0.45     0.00        1.00      0.50     0.40     0.10     0.00        0.30             0.38                0.32     0.07\n",
       "std         0.01         0.03     0.03     0.03     0.09     0.21     0.01        0.02      0.50     0.49     0.29     0.01        0.46             0.48                0.46     0.25\n",
       "min         0.00         0.00     0.00     0.00     0.00     0.00     0.00        0.00      0.00     0.00     0.00     0.00        0.00             0.00                0.00     0.00\n",
       "25%         0.00         0.00     0.00     0.00     0.12     0.30     0.00        1.00      0.00     0.00     0.00     0.00        0.00             0.00                0.00     0.00\n",
       "50%         0.01         0.00     0.00     0.00     0.18     0.44     0.00        1.00      0.50     0.00     0.00     0.00        0.00             0.00                0.00     0.00\n",
       "75%         0.01         0.00     0.00     0.03     0.23     0.59     0.00        1.00      1.00     1.00     0.00     0.00        1.00             1.00                1.00     0.00\n",
       "max         1.00         1.00     1.00     1.00     1.00     1.00     1.00        1.00      1.00     1.00     1.00     1.00        1.00             1.00                1.00     1.00"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Descriptive Statistical Analysis\n",
    "df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   0.93\n",
       "1   0.07\n",
       "Name: lstatus, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.lstatus.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49986, 16)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['annualinc', 'collections', 'delinq', 'inq', 'openacc', 'dti', 'pubrec', 'individual', 'mortgage', 'rent', 'own', 'other', 'term60mths', 'vstatusverified', 'vstatusnotverified', 'lstatus'], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**==================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annualinc</th>\n",
       "      <th>collections</th>\n",
       "      <th>delinq</th>\n",
       "      <th>inq</th>\n",
       "      <th>openacc</th>\n",
       "      <th>dti</th>\n",
       "      <th>pubrec</th>\n",
       "      <th>individual</th>\n",
       "      <th>mortgage</th>\n",
       "      <th>rent</th>\n",
       "      <th>own</th>\n",
       "      <th>other</th>\n",
       "      <th>term60mths</th>\n",
       "      <th>vstatusverified</th>\n",
       "      <th>vstatusnotverified</th>\n",
       "      <th>lstatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   annualinc  collections  delinq  inq  openacc  dti  pubrec  individual  mortgage  rent  own  other  term60mths  vstatusverified  vstatusnotverified  lstatus\n",
       "0       0.01         0.00    0.00 0.00     0.11 0.42    0.00           1         1     0    0      0           0                0                   0        0\n",
       "1       0.01         0.00    0.00 0.03     0.19 0.40    0.00           1         0     1    0      0           0                0                   1        0\n",
       "2       0.01         0.00    0.00 0.00     0.19 0.51    0.00           1         0     1    0      0           0                0                   1        0\n",
       "3       0.01         0.00    0.00 0.00     0.12 0.44    0.00           1         1     0    0      0           0                0                   0        0\n",
       "4       0.01         0.00    0.00 0.03     0.16 0.30    0.00           1         0     1    0      0           1                1                   0        0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12496, 16)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   0.93\n",
       "1   0.07\n",
       "Name: lstatus, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.lstatus.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**==================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**==================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've prepared our data and we're ready to model. There's one last step before we can begin. We must split the data into features and target variable, and into training data and test data. We do this using the `train_test_split()` function. We'll put 25% of the data into our test set, and use the remaining 75% to train the model.\n",
    "\n",
    "Notice below that we include the argument `stratify=y`. If our master data has a class split of 80/20, stratifying ensures that this proportion is maintained in both the training and test data. `=y` tells the function that it should use the class ratio found in the `y` variable (our target).\n",
    "\n",
    "The less data you have overall, and the greater your class imbalance, the more important it is to stratify when you split the data. If we didn’t stratify, then the function would split the data randomly, and we could get an unlucky split that doesn’t get any of the minority class in the test data, which means we wouldn’t be able to effectively evaluate our model. Worst of all, we might not even realize what went wrong without doing some detective work.\n",
    "\n",
    "Lastly, we set a random seed so we and others can reproduce our work.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12496, 16)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,0:15]\n",
    "y = df.iloc[:,15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 11619, 1: 877})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.00533527, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.00751789, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         1.        ],\n",
       "        [0.00897296, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         1.        ],\n",
       "        ...,\n",
       "        [0.01091306, 0.        , 0.        , ..., 1.        , 1.        ,\n",
       "         0.        ],\n",
       "        [0.01321693, 0.        , 0.        , ..., 0.        , 1.        ,\n",
       "         0.        ],\n",
       "        [0.0077604 , 0.        , 0.03703704, ..., 1.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([0, 0, 0, ..., 0, 0, 0], dtype=int64))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.values, y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9996, 15), (2500, 15), (9996,), (2500,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({0: 9294, 1: 702}), Counter({0: 2325, 1: 175}))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_train), Counter(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**==================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Methods (Other Methods)\n",
    "\n",
    "## Univariate Performance with Feature-engine\n",
    "\n",
    "This procedure works as follows:\n",
    "\n",
    "- Train a ML model per every single feature\n",
    "- Determine the performance of the models\n",
    "- Select features if model performance is above a certain threshold\n",
    "\n",
    "The C value in Logistic Regression is an user adjustable parameter that controls regularisation. In simple terms, higher values of C will instruct our model to fit the training set as best as possible, while lower C values will favour a simple models with coefficients closer to zero.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the machine learning model\n",
    "lr = LogisticRegression(penalty='l2', C=1000, random_state=0, solver='lbfgs', max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the selector\n",
    "sel = SelectBySingleFeaturePerformance(\n",
    "    variables=None,\n",
    "    estimator=lr,\n",
    "    scoring=\"roc_auc\",\n",
    "    cv=5,\n",
    "    threshold=0.55\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectBySingleFeaturePerformance(cv=5,\n",
       "                                 estimator=LogisticRegression(C=1000,\n",
       "                                                              max_iter=1000,\n",
       "                                                              random_state=0),\n",
       "                                 threshold=0.55)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find predictive features\n",
    "sel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'annualinc': 0.576822940313442,\n",
       " 'collections': 0.49705241816274925,\n",
       " 'delinq': 0.5073993420109036,\n",
       " 'inq': 0.580084731536066,\n",
       " 'openacc': 0.5099585489358384,\n",
       " 'dti': 0.5278410033828458,\n",
       " 'pubrec': 0.5107032941114253,\n",
       " 'individual': 0.5004841312533621,\n",
       " 'mortgage': 0.5309005216118967,\n",
       " 'rent': 0.529171428991361,\n",
       " 'own': 0.4982371998978737,\n",
       " 'other': 0.5,\n",
       " 'term60mths': 0.5346063947286774,\n",
       " 'vstatusverified': 0.5292979290195733,\n",
       " 'vstatusnotverified': 0.5090316226777127}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the transformer stores a dictionary of feature:metric pairs\n",
    "# notice that the roc can be positive or negative.\n",
    "# the selector selects based on the absolute value\n",
    "\n",
    "#In general, an AUC of 0.5 suggests no discrimination \n",
    "#(i.e., ability to diagnose patients with and without the disease or condition based on the test), \n",
    "#0.7 to 0.8 is considered acceptable, 0.8 to 0.9 is considered excellent, and more than 0.9 is considered outstanding\n",
    "\n",
    "sel.feature_performance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(sel.feature_performance_).sort_values(ascending=False).plot.bar(figsize=(20, 5))\n",
    "plt.title('Performance of ML models trained with individual features', size=15)\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('ROC Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['collections',\n",
       " 'delinq',\n",
       " 'openacc',\n",
       " 'dti',\n",
       " 'pubrec',\n",
       " 'individual',\n",
       " 'mortgage',\n",
       " 'rent',\n",
       " 'own',\n",
       " 'other',\n",
       " 'term60mths',\n",
       " 'vstatusverified',\n",
       " 'vstatusnotverified']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the features that will be removed\n",
    "\n",
    "sel.features_to_drop_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select features in the dataframes\n",
    "\n",
    "X_train = sel.transform(X_train)\n",
    "X_test = sel.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9996, 2), (2500, 2))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['annualinc', 'inq'], dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**==================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Imbalance Treatment\n",
    "\n",
    "For many machine learning tasks on imbalanced datasets, like this credit card fraud detection, we normally care more about recall than precision. As a baseline, we want the model to be able to find all frauds and we would allow the model to make false-positive errors because the cost of false positives is usually not very high (maybe just costs a false notification email or phone call to confirm with customers). On the other hand, failing to recognize positive examples (such as fraud or a deadly disease) can be life-threatening \n",
    "\n",
    "As such, our priority is to improve the model's recall, then we will also want to keep precision as high as possible.\n",
    "\n",
    "## Class reweighting\n",
    "\n",
    "For binary classification models, its loss function is normally calculated via a sum of the loss with respect to class 0 and the loss with respect to class 1. By default, their class weights are all 1s meaning we treat each class equally important.\n",
    "\n",
    "However, since the class distribution is skewed in imbalanced datasets and the loss function optimization process will be dominated by the majority class, we want to help the minority class by increasing its class weight in the loss function.\n",
    "\n",
    "Class weights can be generally calculated via the following three strategies:\n",
    "\n",
    "- Based on their instances portion in the dataset. For example, if positive instances only take 10% of the dataset, we assign its weight to be 0.9 and weight for the majority class to be 0.1\n",
    "- Heuristics or domain knowledge. Misclassification normally has different costs per class, for example, the cost of failure to diagnose a disease is much higher than a false positive diagnose. If we already know such misclassification costs beforehand, we may use them to assign class weights\n",
    "- Hyper-parameter tuning. Standard hyper-parameter tuning methods can be used to find optimized class weights. For example, grid searching from 0.1 to 0.9 for positive class weight to find out which hyperparameter combination generates the best model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = {}\n",
    "\n",
    "# Assign weight of class 0 to be 0.1\n",
    "class_weight[0] = 0.1\n",
    "\n",
    "# Assign weight of class 1 to be 0.9\n",
    "class_weight[1] = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a logistic regression with weight\n",
    "logregw = LogisticRegression(random_state=0, \n",
    "                              max_iter = 1000,\n",
    "                              class_weight=class_weight,\n",
    "                              C=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight={0: 0.1, 1: 0.9}, max_iter=1000, random_state=0)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "logregw.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test dataset\n",
    "logregw_pred = logregw.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logregw_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.930\n",
      "Precision: 0.333\n",
      "Recall: 0.006\n",
      "F1 Score: 0.011\n",
      "ROC-AUC Score: 0.502\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", \"%.3f\" % accuracy_score(y_test, logregw_pred))\n",
    "print(\"Precision:\", \"%.3f\" % precision_score(y_test, logregw_pred))\n",
    "print(\"Recall:\", \"%.3f\" % recall_score(y_test, logregw_pred))\n",
    "print(\"F1 Score:\", \"%.3f\" % f1_score(y_test, logregw_pred))\n",
    "print(\"ROC-AUC Score:\", \"%.3f\" % roc_auc_score(y_test, logregw_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression (Scikit Learn)\n",
    "\n",
    "**Logistic Regression model assumptions**\n",
    "- Outcome variable is categorical\n",
    "- Observations are independent of each other\n",
    "- No severe multicollinearity among X variables\n",
    "- No extreme outliers\n",
    "- Linear relationship between each X variable and the logit of the outcome variable\n",
    "- Sufficiently large sample size\n",
    "\n",
    "Let's build our model using **LogisticRegression** from the Scikit-learn package. This function implements logistic regression and can use different numerical optimizers to find parameters, including ‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’ solvers. You can find extensive information about the pros and cons of these optimizers if you search it in the internet.\n",
    "\n",
    "The version of Logistic Regression in Scikit-learn, support regularization. Regularization is a technique used to solve the overfitting problem of machine learning models.\n",
    "**C** parameter indicates **inverse of regularization strength** which must be a positive float. Smaller values specify stronger regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "## RandomSearchCV\n",
    "\n",
    "Randomised grid search is very useful in finding near-optimal hyper parameters for any machine learning models.\n",
    "\n",
    "Rules of thumb: with 60 iterations, 95% of the time, best 5% sets of parameters can be found, regardless of grid size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(max_iter=1000, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = { 'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "               'penalty' : ['none', 'l1', 'l2', 'elasticnet'],\n",
    "               'C':  [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {'accuracy', 'precision', 'recall', 'f1', 'roc_auc'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_randm = RandomizedSearchCV(estimator=logreg, param_distributions = parameters, cv = 5, n_iter = 50, \n",
    "                           n_jobs=-1, scoring=scoring, refit='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lr_randm.fit(X_random_train, y_random_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_randm.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_randm.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_randm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_results(model_name:str, model_object, metric:str):\n",
    "    '''\n",
    "    Arguments:\n",
    "        model_name (string): what you want the model to be called in the output table\n",
    "        model_object: a fit GridSearchCV object\n",
    "        metric (string): precision, recall, f1, accuracy, or auc\n",
    "  \n",
    "    Returns a pandas df with the F1, recall, precision, accuracy, and auc scores\n",
    "    for the model with the best mean 'metric' score across all validation folds.  \n",
    "    '''\n",
    "\n",
    "    # Create dictionary that maps input metric to actual metric name in GridSearchCV\n",
    "    metric_dict = {\n",
    "                 'precision': 'mean_test_precision',\n",
    "                 'recall': 'mean_test_recall',\n",
    "                 'f1': 'mean_test_f1',\n",
    "                 'accuracy': 'mean_test_accuracy',\n",
    "                 'roc_auc' : 'mean_test_roc_auc'\n",
    "                 }\n",
    "\n",
    "    # Get all the results from the CV and put them in a df\n",
    "    cv_results = pd.DataFrame(model_object.cv_results_)\n",
    "\n",
    "    # Isolate the row of the df with the max(metric) score\n",
    "    best_estimator_results = cv_results.iloc[cv_results[metric_dict[metric]].idxmax(), :]\n",
    "\n",
    "    # Extract Accuracy, precision, recall, and f1 score from that row\n",
    "    \n",
    "    f1 = best_estimator_results.mean_test_f1\n",
    "    recall = best_estimator_results.mean_test_recall\n",
    "    precision = best_estimator_results.mean_test_precision\n",
    "    accuracy = best_estimator_results.mean_test_accuracy\n",
    "    roc_auc = best_estimator_results.mean_test_roc_auc\n",
    "  \n",
    "    # Create table of results\n",
    "    table = pd.DataFrame()\n",
    "    table = table.append({'Model': model_name,\n",
    "                        'Precision': precision,\n",
    "                        'Recall': recall,\n",
    "                        'F1': f1,\n",
    "                        'Accuracy': accuracy,\n",
    "                        'ROC-AUC' : roc_auc\n",
    "                        },\n",
    "                        ignore_index=True\n",
    "                       )\n",
    "  \n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all CV scores\n",
    "lr_cv_results = make_results('Logistic Regression', lr_randm, 'roc_auc')\n",
    "lr_cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression( penalty='l1', C=0.1, max_iter=1000, random_state=0, solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_pred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,logreg_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test,logreg_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(estimator=logreg, X=X_test, y=y_test, ax=ax, display_labels=[\"No\",\"Yes\"])\n",
    "ax.set_title('Confusion matrix of the classifier', size=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "\n",
    "RocCurveDisplay.from_estimator(estimator=logreg, X=X_test, y=y_test, ax=ax)\n",
    "ax.set_title('ROC Curve of the classifier', size=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate the generalization error of a machine learning model using Cross-Validation Schemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold Cross-Validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate generalization error\n",
    "clf = cross_validate(estimator=logregl1,\n",
    "                    X=X_train,\n",
    "                    y=y_train,\n",
    "                    scoring='roc_auc',\n",
    "                    return_train_score=True,\n",
    "                    cv=kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean test set roc-auc\n",
    "clf[\"test_score\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean train set roc-auc\n",
    "clf[\"train_score\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrtable = pd.DataFrame()\n",
    "lrtable = table.append({'Model': \"Logistic Regression\",\n",
    "                        'F1':  f1_score(y_test, logreg_pred),\n",
    "                        'Recall': recall_score(y_test, logreg_pred),\n",
    "                        'Precision': precision_score(y_test, logreg_pred),\n",
    "                        'Accuracy': accuracy_score(y_test, logreg_pred),\n",
    "                        'ROC-AUC': roc_auc_score(y_test, logreg_pred)\n",
    "                      },\n",
    "                        ignore_index=True)\n",
    "                     \n",
    "lrtable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**==================================================================================================================**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L1 regularized logistic regression\n",
    "logregl1 = LogisticRegression(penalty='l1', C=1.0, \n",
    "                              solver='liblinear', class_weight=None,\n",
    "                              max_iter=1000, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logregl1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logregl1_pred = logregl1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logregl1_pred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logregl1.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logregl1.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logregl1.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logregl1.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**==================================================================================================================**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L2 regularized logistic regression\n",
    "logregl2 = LogisticRegression(penalty='l2', C=1.0, solver='liblinear', max_iter=500, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logregl2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logregl2_pred = logregl2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logregl2_pred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logregl2.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logregl2.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logregl2.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logregl2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find best C value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "# try c values from 0.001 to 100:\n",
    "c_settings = np.arange(0.001, 100, 0.1) \n",
    "for i in c_settings:\n",
    "    # build the model\n",
    "    clf = LogisticRegression(C=i)\n",
    "    clf.fit(X_train, y_train)\n",
    "    # record training set accuracy\n",
    "    training_accuracy.append(clf.score(X_train, y_train))\n",
    "    # record generalization accuracy\n",
    "    test_accuracy.append(clf.score(X_test, y_test))\n",
    "    \n",
    "plt.plot(c_settings, training_accuracy, label=\"training accuracy\")\n",
    "plt.plot(c_settings, test_accuracy, label=\"test accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine which evaluation metric might be best, consider how our model might be wrong. There are two possibilities for bad predictions: \n",
    "  \n",
    "  - **False positives:** When the model predicts a customer **will** churn when in fact they won't\n",
    "  - **False negatives:** When the model predicts a customer will **not** churn when in fact they will     \n",
    "\n",
    "As you know, there are a number of performance metrics aside from accuracy to choose from. Some of these include precision, recall, and F1 score. Let's examine these more closely, beginning with _precision_:\n",
    "\n",
    "$$precision = \\frac{\\text{TP}}{\\text{FP+TP}}$$\n",
    "  </br> \n",
    "\n",
    "And _recall_: \n",
    "\n",
    "$$recall = \\frac{\\text{TP}}{\\text{FN+TP}}$$  \n",
    "  </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"confusion matrix.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision represents the percentage of all our model's predicted positives that are true positives. This might not be the best metric for us to use, because it disincentivizes predicting someone will churn unless there is a high degree of certainty that they will. This could translate to a high rate of false negatives.\n",
    "\n",
    "On the other hand, recall represents the percentage of all actual positives that the model identifies as such. This also might not be the best metric to use, because it rewards predicting someone will churn even if the likelihood of their doing so is very small. This could translate to a high rate of false positives.\n",
    "\n",
    "So which is worse, false positives or false negatives? Well, we'd first have to define what _worse_ means. This is dependent on the details of the project that you're working on. For the sake of this exercise, let us suppose that we're defining it as the error that would cost the bank more money.\n",
    "\n",
    "Since we don't know the exact cost of predicting a false negative, we'll make an assumption for this exercise. We'll assume that a metric that balances precision and recall is best. The metric that helps us achieve this balance is _F1 score_, which is defined as the harmonic mean of precision and recall. \n",
    "\n",
    "$${F_{1}} = 2 \\cdot \\frac{precision \\cdot  recall}{precision + recall}$$  \n",
    "</br>\n",
    "Again, there are many metrics to choose from. The important thing is that you make an informed decision that is based on your use case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What are the four basic parameters for evaluating the performance of a classification model?\n",
    "\n",
    "1. True positives (TP): These are correctly predicted positive values, which means the value of actual and predicted classes are positive. \n",
    "\n",
    "2. True negatives (TN): These are correctly predicted negative values, which means the value of the actual and predicted classes are negative.\n",
    "\n",
    "3. False positives (FP): This occurs when the value of the actual class is negative and the value of the predicted class is positive.\n",
    "\n",
    "4. False negatives (FN): This occurs when the value of the actual class is positive and the value of the predicted class in negative. \n",
    "\n",
    "**Reminder:** When fitting and tuning classification modeld, data professioals aim to minimize false positives and false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:**  What do the four scores demonstrate about your model, and how do you calculate them?\n",
    "\n",
    "- Accuracy (TP+TN/TP+FP+FN+TN): The ratio of correctly predicted observations to total observations. \n",
    " \n",
    "- Precision (TP/TP+FP): The ratio of correctly predicted positive observations to total predicted positive observations. \n",
    "\n",
    "- Recall (Sensitivity, TP/TP+FN): The ratio of correctly predicted positive observations to all observations in actual class.\n",
    "\n",
    "- F1 score: The harmonic average of precision and recall, which takes into account both false positives and false negatives. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,logregl1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test,logregl1_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(estimator=logregl1, X=X_test, y=y_test, ax=ax, display_labels=[\"No\",\"Yes\"])\n",
    "ax.set_title('Confusion matrix of the classifier', size=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "\n",
    "RocCurveDisplay.from_estimator(estimator=logregl1, X=X_test, y=y_test, ax=ax)\n",
    "ax.set_title('ROC Curve of the classifier', size=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jaccard index\n",
    "\n",
    "Let's try the jaccard index for accuracy evaluation. we can define jaccard as the size of the intersection divided by the size of the union of the two label sets. If the entire set of predicted labels for a sample strictly matches with the true set of labels, then the subset accuracy is 1.0; otherwise it is 0.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard_score(y_test, logpred , pos_label=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Loss\n",
    "\n",
    "Now, let's try **log loss** for evaluation. In logistic regression, the output can be the probability of customer churn is yes (or equals to 1). This probability is a value between 0 and 1.\n",
    "Log loss(Logarithmic loss) measures the performance of a classifier where the predicted output is a probability value between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logproba = logreg.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss(y_test, logproba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze the results\n",
    "\n",
    "Print out the model's accuracy, precision, recall, and F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\", \"%.3f\" % accuracy_score(y_test, logregl1_pred))\n",
    "print(\"Precision:\", \"%.3f\" % precision_score(y_test, logregl1_pred))\n",
    "print(\"Recall:\", \"%.3f\" % recall_score(y_test, logregl1_pred))\n",
    "print(\"F1 Score:\", \"%.3f\" % f1_score(y_test, logregl1_pred))\n",
    "print(\"ROC-AUC Score:\", \"%.3f\" % roc_auc_score(y_test, logregl1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.DataFrame()\n",
    "table = table.append({'Model': \"Logistic Regression\",\n",
    "                        'F1':  f1_score(y_test, logregl1_pred),\n",
    "                        'Recall': recall_score(y_test, logregl1_pred),\n",
    "                        'Precision': precision_score(y_test, logregl1_pred),\n",
    "                        'Accuracy': accuracy_score(y_test, logregl1_pred),\n",
    "                        'ROC-AUC': roc_auc_score(y_test, logregl1_pred)\n",
    "                      },\n",
    "                        ignore_index=True)\n",
    "                     \n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation\n",
    "\n",
    "When performing supervised machine learning analysis, it is common to withhold a portion of the data to test the final model's performance. This model testing is performed on the 'unseen' data, which the model was not trained on. This withholding of a portion of the dataset for testing is called Cross-Validation. Cross-Validation can also be used to select hyper-parameters and test the final model. In this section, we will focus on the test data only.\n",
    "\n",
    "Cross-Validation also helps avoid over-fitting; a complex model could repeat the labels of the samples that it has just seen and, therefore, would have a perfect score but would fail to predict anything useful on the 'unseen' data. Furthermore, a complex model could just be modeling noise.\n",
    "\n",
    "Cross validation method involves dividing the dataset into 3 parts:\n",
    "\n",
    "*   training set - is a portion of the data used for training the model\n",
    "*   validation set - is a portion of the data used to optimize the hyper-parameters of the model. This will     be illustrated in the next lab\n",
    "*   test set - is a portion of the data used to evaluate if the model generalizes enough to work on the     \n",
    "    data it was not trained on   \n",
    "    \n",
    "`Scikit Learn` library contains many methods that can perform the splitting of the data into training, testing and validation sets. The most popular methods that we will cover in this Jupyter Notebook are:\n",
    "\n",
    "*   train_test_split - creates a single split into train and test sets\n",
    "*   K-fold - creates number of k-fold splits, allowing cross validation\n",
    "*   cross_val_score - evaluates model's score through cross validation\n",
    "\n",
    "[`cross_val_predict`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML240ENSkillsNetwork783-2023-01-01) is a function that does K-fold cross validation for us, appropriately fitting and transforming at every step of the way.\n",
    "\n",
    "Note that `cross_val_predict` doesn't use the same model for all steps; the predictions for each row are made when that row is in the validation set. We really have the collected results of 3 (i.e. `kf.num_splits`) different models. \n",
    "\n",
    "When we are done, `estimator` is still not fitted. If we want to predict on _new_ data, we still have to train our `estimator`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Fold Cross Validation\n",
    "\n",
    "Cross-validation is a resampling procedure used to evaluate machine learning models on a limited data sample.\n",
    "\n",
    "The procedure has a single parameter called k that refers to the number of groups that a given data sample is to be split into. As such, the procedure is often called k-fold cross-validation. When a specific value for k is chosen, it may be used in place of k in the reference to the model, such as k=5 becoming 5-fold cross-validation, as shown in the Diagram below. In this case, we would use K-1 (or 4 folds) for testing a 1 fold for training. K-fold is also used for hyper-parameters selection that we will discuss later.\n",
    "\n",
    "<img src=\"k-fold.png\">\n",
    "<img src = \"cross_validation_diagram.png\">\n",
    "\n",
    "In many cases, we would like to train models that are not available in Scikit-learn or are too large to fit in the memory. We can create a `KFold` object that  Provides train/test indices to split data into train/test sets in an iterative manner.\n",
    "\n",
    "`n_splits`:  A number of folds. Must be at least 2. Changed in version 0.22: n_splits default value changed from 3 to 5.\n",
    "\n",
    "`shuffle`: Indicates whether to shuffle the data before splitting into batches. Note, the samples within each split will not be shuffled.\n",
    "\n",
    "`random_state`: the random state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate the generalization error of a machine learning model using Cross-Validation Schemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold Cross-Validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate generalization error\n",
    "clf = cross_validate(estimator=logregl1,\n",
    "                    X=X_train,\n",
    "                    y=y_train,\n",
    "                    scoring='roc_auc',\n",
    "                    return_train_score=True,\n",
    "                    cv=kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean test set roc-auc\n",
    "clf[\"test_score\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean train set roc-auc\n",
    "clf[\"train_score\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation Score\n",
    "\n",
    "Now, let's use *Scikit-Learn's* *K-fold cross-validation* method to see whether we can assess the performance of our model. The *K-fold cross-validation* method splits the training set into the number of folds (n_splits), as now in the Diagram above, if we have K folds, K-1 is used for training and one fold is used for testing. The input parameters are as follows:\n",
    "\n",
    "<b>estimator</b>: The object to use to `fit` the data.\n",
    "\n",
    "<b>X</b>: array-like of shape (n_samples, n_features). The data to fit. Can be for example a list, or an array.\n",
    "\n",
    "<b>y</b>: array-like of shape (n_samples,) or (n_samples, n_outputs), default=None. The target variable to try to predict in the case of supervised learning.\n",
    "\n",
    "<b>scoring</b>: A str or a scorer callable object/ function with signature scorer (estimator, X, y) which should return only a single value.  See model evaluation [documentation](https://scikit-learn.org/stable/modules/model_evaluation.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML240ENSkillsNetwork34171862-2022-01-01#scoring-parameter) for more information.\n",
    "\n",
    "The larger the fold, the better the model performance is, as we are using more samples for training; the variance also decreases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv = cross_val_score(estimator=logreg, X=X_train, y=y_train, scoring='accuracy', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv = cross_val_score(estimator=logreg, X=X_train, y=y_train, scoring='f1', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-1 * cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the function 'cross_val_predict' to predict the output. The function splits up the data into the specified number of folds, with one fold for testing and the other folds are used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logreg_pred_cv = cross_val_predict(estimator=logreg, X=X_train[[\"disp\"]], y=y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logreg_pred_cv [0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validated hyperparameter tuning\n",
    "\n",
    "Cross-validating a model using GridSearchCV can be done in a number of different ways. If you find notebooks online that other people have written, you'll likely soon discover this for yourself. But all variations must fulfill the same general requirements. (Refer to the [GridSearchCV documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV) for further reading.)\n",
    "\n",
    "The format presented below is step-wise, making it easier to follow.\n",
    "\n",
    "* Create a dictionary of hyperparameters to search over:\n",
    "\n",
    "  - key = name of hyperparameter (string)\n",
    "  - value = values to search over (list)\n",
    "  \n",
    "* Create a dictionary of scoring metrics to capture. These metrics can be selected from scikit-learn's [built-in options](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter) or custom-defined. For this exercise, we'll capture accuracy, precision, recall, and F1 score so we can examine all of them. The metrics are entered as strings.\n",
    "\n",
    "* Instantiate the classifier (and set the `random_state`)\n",
    "\n",
    "* Instantiate the `GridSearchCV` object. Pass as arguments:\n",
    "  - The classifier (`tuned_decision_tree`)\n",
    "  - The dictionary of hyperparameters to search over (`tree_para`)\n",
    "  - The dictionary of scoring metrics (`scoring`)\n",
    "  - The number of cross-validation folds you want (`cv=5`)\n",
    "  - The scoring metric that you want GridSearch to use when it selects the \"best\" model (i.e., the model that performs best on average over all validation folds) (`refit='f1'`*)\n",
    "\n",
    "    \\* The reason it's called `refit` is because once the algorithm finds the combination of hyperparameters that results in the best average score across all validation folds, it will then refit this model to _all_ of the training data. Remember, up until now, with a 5-fold cross-validation, the model has only ever been fit on 80% (4/5) of the training data, because the remaining 20% was held out as a validation fold.\n",
    "\n",
    "* Fit the data (`X_train`, `y_train`) to the `GridSearchCV` object (`clf`)\n",
    "\n",
    "Depending on the number of different hyperparameters you choose, the number of combinations you search over, the size of your data, and your available computing resources, this could take a long time.\n",
    "\n",
    "Now that the model is fit and cross-validated, we can use the `best_estimator_` attribute to inspect the hyperparameter values that yielded the highest F1 score during cross-validation.\n",
    "\n",
    "The `best_score_` attribute returns the best average F1 score across the different folds among all the combinations of hyperparameters. Note that if we had set `refit='recall'` when we instantiated our `GridSearchCV` object earlier, then calling `best_score_` would return the best recall score, and the best parameters might not be the same as what they are in the above cell, because the model would be selected based on a different metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the model\n",
    "logreg = LogisticRegression(penalty='l1', C=1.0, \n",
    "                              solver='liblinear', class_weight=None,\n",
    "                              max_iter=1000, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the hyperparameter space\n",
    "param_grid = dict(\n",
    "    class_weight=[{0:0.05, 1:0.95}, {0:0.1, 1:0.9}, {0:0.2, 1:0.8}, {0:0.3, 1:0.7}, {0:0.3, 1:0.6}],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {'accuracy', 'precision', 'recall', 'f1', 'roc_auc'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the search (one score)\n",
    "gs1 = GridSearchCV(estimator=logreg, param_grid=param_grid, scoring='roc_auc', \n",
    "                  n_jobs=2, refit=True, cv=5, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the search (multiple scores)\n",
    "gs2 = GridSearchCV(estimator=logreg, param_grid=param_grid, scoring=scoring, \n",
    "                  n_jobs=2, refit='roc_auc', cv=5, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find best hyperparameters\n",
    "gs1.fit(X_random_train, y_random_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find best hyperparameters\n",
    "gs2.fit(X_random_train, y_random_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the best hyperparameters are stored in an attribute\n",
    "\n",
    "gs1.best_estimator_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the best hyperparameters are stored in an attribute\n",
    "\n",
    "gs2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we also find the data for all models evaluated\n",
    "\n",
    "results = pd.DataFrame(gs2.cv_results_)\n",
    "\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_results(model_name:str, model_object, metric:str):\n",
    "    '''\n",
    "    Arguments:\n",
    "        model_name (string): what you want the model to be called in the output table\n",
    "        model_object: a fit GridSearchCV object\n",
    "        metric (string): precision, recall, f1, accuracy, or auc\n",
    "  \n",
    "    Returns a pandas df with the F1, recall, precision, accuracy, and auc scores\n",
    "    for the model with the best mean 'metric' score across all validation folds.  \n",
    "    '''\n",
    "\n",
    "    # Create dictionary that maps input metric to actual metric name in GridSearchCV\n",
    "    metric_dict = {\n",
    "                 'precision': 'mean_test_precision',\n",
    "                 'recall': 'mean_test_recall',\n",
    "                 'f1': 'mean_test_f1',\n",
    "                 'accuracy': 'mean_test_accuracy',\n",
    "                 'roc_auc' : 'mean_test_roc_auc'\n",
    "                 }\n",
    "\n",
    "    # Get all the results from the CV and put them in a df\n",
    "    cv_results = pd.DataFrame(model_object.cv_results_)\n",
    "\n",
    "    # Isolate the row of the df with the max(metric) score\n",
    "    best_estimator_results = cv_results.iloc[cv_results[metric_dict[metric]].idxmax(), :]\n",
    "\n",
    "    # Extract Accuracy, precision, recall, and f1 score from that row\n",
    "    \n",
    "    f1 = best_estimator_results.mean_test_f1\n",
    "    recall = best_estimator_results.mean_test_recall\n",
    "    precision = best_estimator_results.mean_test_precision\n",
    "    accuracy = best_estimator_results.mean_test_accuracy\n",
    "    roc_auc = best_estimator_results.mean_test_roc_auc\n",
    "  \n",
    "    # Create table of results\n",
    "    table = pd.DataFrame()\n",
    "    table = table.append({'Model': model_name,\n",
    "                        'Precision': precision,\n",
    "                        'Recall': recall,\n",
    "                        'F1': f1,\n",
    "                        'Accuracy': accuracy,\n",
    "                        'ROC-AUC' : roc_auc\n",
    "                        },\n",
    "                        ignore_index=True\n",
    "                       )\n",
    "  \n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_cv_results = make_results(\"GS Logistic Regression\", model_object=gs2, metric=\"roc_auc\")\n",
    "lr_cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(max_iter=1000, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = { 'solver' : ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "               'penalty' : ['none','l1', 'l2', 'elasticnet'],\n",
    "               'C':  [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {'accuracy', 'precision', 'recall', 'f1', 'roc_auc'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_randm = RandomizedSearchCV(estimator=logreg, param_distributions = parameters, cv = 5, n_iter = 40, \n",
    "                           n_jobs=-1, scoring=scoring, refit='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lr_randm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_randm.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_randm.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_randm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_results(model_name:str, model_object, metric:str):\n",
    "    '''\n",
    "    Arguments:\n",
    "        model_name (string): what you want the model to be called in the output table\n",
    "        model_object: a fit GridSearchCV object\n",
    "        metric (string): precision, recall, f1, accuracy, or auc\n",
    "  \n",
    "    Returns a pandas df with the F1, recall, precision, accuracy, and auc scores\n",
    "    for the model with the best mean 'metric' score across all validation folds.  \n",
    "    '''\n",
    "\n",
    "    # Create dictionary that maps input metric to actual metric name in GridSearchCV\n",
    "    metric_dict = {\n",
    "                 'precision': 'mean_test_precision',\n",
    "                 'recall': 'mean_test_recall',\n",
    "                 'f1': 'mean_test_f1',\n",
    "                 'accuracy': 'mean_test_accuracy',\n",
    "                 'roc_auc' : 'mean_test_roc_auc'\n",
    "                 }\n",
    "\n",
    "    # Get all the results from the CV and put them in a df\n",
    "    cv_results = pd.DataFrame(model_object.cv_results_)\n",
    "\n",
    "    # Isolate the row of the df with the max(metric) score\n",
    "    best_estimator_results = cv_results.iloc[cv_results[metric_dict[metric]].idxmax(), :]\n",
    "\n",
    "    # Extract Accuracy, precision, recall, and f1 score from that row\n",
    "    \n",
    "    f1 = best_estimator_results.mean_test_f1\n",
    "    recall = best_estimator_results.mean_test_recall\n",
    "    precision = best_estimator_results.mean_test_precision\n",
    "    accuracy = best_estimator_results.mean_test_accuracy\n",
    "    roc_auc = best_estimator_results.mean_test_roc_auc\n",
    "  \n",
    "    # Create table of results\n",
    "    table = pd.DataFrame()\n",
    "    table = table.append({'Model': model_name,\n",
    "                        'Precision': precision,\n",
    "                        'Recall': recall,\n",
    "                        'F1': f1,\n",
    "                        'Accuracy': accuracy,\n",
    "                        'ROC-AUC' : roc_auc\n",
    "                        },\n",
    "                        ignore_index=True\n",
    "                       )\n",
    "  \n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all CV scores\n",
    "lr_cv_results = make_results('Logistic Regression', lr_randm, 'roc_auc')\n",
    "lr_cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyCaret Binary Classification Tutorial\n",
    "\n",
    "PyCaret is an open-source, low-code machine learning library in Python that automates machine learning workflows. It is an end-to-end machine learning and model management tool that exponentially speeds up the experiment cycle and makes you more productive.\n",
    "\n",
    "Compared with the other open-source machine learning libraries, PyCaret is an alternate low-code library that can be used to replace hundreds of lines of code with a few lines only. This makes experiments exponentially fast and efficient. PyCaret is essentially a Python wrapper around several machine learning libraries and frameworks, such as scikit-learn, XGBoost, LightGBM, CatBoost, spaCy, Optuna, Hyperopt, Ray, and a few more.\n",
    "\n",
    "The design and simplicity of PyCaret are inspired by the emerging role of citizen data scientists, a term first used by Gartner. Citizen Data Scientists are power users who can perform both simple and moderately sophisticated analytical tasks that would previously have required more technical expertise.\n",
    "\n",
    "Once the setup has been successfully executed it shows the information grid containing experiment level information. \n",
    "\n",
    "- **Session id:**  A pseudo-random number distributed as a seed in all functions for later reproducibility. If no `session_id` is passed, a random number is automatically generated that is distributed to all functions.<br/>\n",
    "<br/>\n",
    "- **Target type:**  Binary, Multiclass, or Regression. The Target type is automatically detected. <br/>\n",
    "<br/>\n",
    "- **Label Encoding:**  When the Target variable is of type string (i.e. 'Yes' or 'No') instead of 1 or 0, it automatically encodes the label into 1 and 0 and displays the mapping (0 : No, 1 : Yes) for reference. In this tutorial, no label encoding is required since the target variable is of numeric type. <br/>\n",
    "<br/>\n",
    "- **Original data shape:**  Shape of the original data prior to any transformations. <br/>\n",
    "<br/>\n",
    "- **Transformed train set shape :**  Shape of transformed train set <br/>\n",
    "<br/>\n",
    "- **Transformed test set shape :**  Shape of transformed test set <br/>\n",
    "<br/>\n",
    "- **Numeric features :**  The number of features considered as numerical. <br/>\n",
    "<br/>\n",
    "- **Categorical features :**  The number of features considered as categorical. <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = setup(data=df, target = 'lstatus', session_id = 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Models\n",
    "\n",
    "This function trains and evaluates the performance of all the estimators available in the model library using cross-validation. The output of this function is a scoring grid with average cross-validated scores. Metrics evaluated during CV can be accessed using the `get_metrics` function. Custom metrics can be added or removed using `add_metric` and `remove_metric` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare baseline models\n",
    "best = compare_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Model\n",
    "\n",
    "You can use the `plot_model` function to analyzes the performance of a trained model on the test set. It may require re-training the model in certain cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot confusion matrix\n",
    "plot_model(best, plot = 'confusion_matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot AUC\n",
    "plot_model(best, plot = 'auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot feature importance\n",
    "plot_model(best, plot = 'feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "The `predict_model` function returns `prediction_label` and `prediction_score` (probability of the predicted class) as new columns in dataframe. When data is `None` (default), it uses the test set (created during the setup function) for scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test set\n",
    "holdout_pred = predict_model(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show predictions df\n",
    "holdout_pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same function works for predicting the labels on unseen dataset. Let's create a copy of original data and drop the `Class variable`. We can then use the new data frame without labels for scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy data and drop Class variable\n",
    "\n",
    "new_data = data.copy()\n",
    "new_data.drop('Class variable', axis=1, inplace=True)\n",
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict model on new_data\n",
    "predictions = predict_model(best, data = new_data)\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model\n",
    "\n",
    "Finally, you can save the entire pipeline on disk for later use, using pycaret's `save_model` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save pipeline\n",
    "save_model(best, 'my_first_pipeline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pipeline\n",
    "loaded_best_pipeline = load_model('my_first_pipeline')\n",
    "loaded_best_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python code done by Dennis Lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
